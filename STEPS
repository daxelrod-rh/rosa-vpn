First apply pre-vpn
oc apply -f yaml/service.yml
oc describe service ipsec -n vpn-infra
# Look for LoadBalancer Ingress
nslookup above ingress
Put IP in VPN part of terraform
oc apply -f yaml/1-virt-operator.yaml
oc apply -f yaml/2-virt-hyperconverged.yaml
oc apply -f yaml/cudn.yaml
Create VM "ipsec" in "vpn-infra"
    centos stream 10
    network -> Add network interface
        Name cudn
        Network: vm-network

On "ipsec"
    sudo yum install -y libreswan
    Add contents of files/ipsec/etc/ipsec.d/aws.conf to ipsec:/etc/ipsec.d/aws.conf
    Create ipsec:/etc/ipsec.d/aws.secrets with secret from AWS's config
    sudo systemctl enable ipsec
    sudo systemctl start ipsec
    nmcli con add type ethernet ifname enp2s0 con-name cudn ipv4.addresses 192.168.1.10/24 ipv4.method manual autoconnect yes
    nmcli con mod cudn 802-3-ethernet.mtu 1400
    nmcli con up cudn

    **ip forwarding**

    #runtime
    sudo sysctl -w net.ipv4.ip_forward=1

    #persist
    echo "net.ipv4.ip_forward=1" | sudo tee /etc/sysctl.d/91-ip-forward.conf >/dev/null
    sudo sysctl -p /etc/sysctl.d/91-ip-forward.conf

    
    **ensure that RPF is loose on both NICs + global**
    
    #runtime
    sudo sysctl -w net.ipv4.conf.all.rp_filter=2
    sudo sysctl -w net.ipv4.conf.default.rp_filter=2
    sudo sysctl -w net.ipv4.conf.enp1s0.rp_filter=2   # AWS side NIC

    #persist
    echo -e "net.ipv4.conf.all.rp_filter=2\nnet.ipv4.conf.default.rp_filter=2\nnet.ipv4.conf.enp1s0.rp_filter=2\nnet.ipv4.conf.enp2s0.rp_filter=2" | sudo tee /etc/sysctl.d/90-multihome.conf >/dev/null
    sudo sysctl -p /etc/sysctl.d/90-multihome.conf

    #restart
    sudo systemctl restart ipsec


    **add return route on the CUDN side**
    make sure the CUDN router/host has "ip route add 10.10.0.0/16 via 192.168.1.10" (without the return path, pings will fail even if the AWS side is perfect)


On cluster

    **find nodeports**
    ruun "oc -n vpn-infra get svc ipsec -o jsonpath='{range .spec.ports[*]}{.name}:{.port}->{.nodePort}{"\n"}{end}'"

On AWS Console

    **adjust route tables on the VPC**
    make sure that AWS VPN shows a route to 192.168.1.0/24 and your VPC route table has a propagated/explicit route to that prefix via the VGW (be sure to add this IP on every route table, incl. private/public one(s), and choose the correspondent virtual gateway)

    **adjust security groups**
    add inbound rules as follows:
    - UDP <nodePort-for-500> from 18.204.200.100/32, 52.20.28.136/32 (tunnel outside IPs) 
    - UDP <nodePort-for-4500> from the same sources 
    - allow from the VPC CIDR for NLB health checks (?)
    - ICMP from CUDN (192.168.1.0/24) 
    - TCP 22 (optional, for ssh) from CUDN
    - TCP 80 (to curl httpd) from CUDN
    - TCP 30000–32767 from CUDN


Troubleshooting steps

    # remove no-op route
    sudo ip route del 10.10.0.0/16 || true

    # remove Windows CRLF just in case
    sudo sed -i -e 's/\r$//' /etc/ipsec.conf /etc/ipsec.secrets /etc/ipsec.d/*.conf /etc/ipsec.d/*.secrets 2>/dev/null

    # perms
    sudo chmod 644 /etc/ipsec.d/*.conf 2>/dev/null || true
    sudo chmod 600 /etc/ipsec.secrets /etc/ipsec.d/*.secrets 2>/dev/null || true

    # SELinux labels
    sudo restorecon -Rv /etc/ipsec.conf /etc/ipsec.secrets /etc/ipsec.d >/dev/null

    # relax RP filter
    echo -e "net.ipv4.conf.all.rp_filter=0\nnet.ipv4.conf.default.rp_filter=0" | sudo tee /etc/sysctl.d/99-ipsec.conf
    sudo sysctl -p /etc/sysctl.d/99-ipsec.conf


Generic steps:
1. Create CGW matching cluster's egress IP (login to cluster and run "curl -s https://checkip.amazonaws.com | tr -d '\r'")
2. Create VGW and attach it to ROSA VPC
3. Create VPN S2S
4. Create CUDN VM
5. Create EC2 (or bastion) host if not already:
    - Create a dedicated SG where for the inbound rule: type All ICMP – IPv4, Source 192.168.1.0/24 (you can tighten later). Egress is usually “All traffic / 0.0.0.0/0” by default — that’s fine.











